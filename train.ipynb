{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from model import UNet, DiscConvNet\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "from dataBatcher import *\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 520\n"
     ]
    }
   ],
   "source": [
    "input_file_names, target_file_names = readFileNames()\n",
    "input_file_names_train = input_file_names[0:2000] # 2000 files used for training\n",
    "target_file_names_train = target_file_names[0:2000]\n",
    "input_file_names_test = input_file_names[2000:] # remaining 520 files used for validation\n",
    "target_file_names_test = target_file_names[2000:]\n",
    "train_size = len(input_file_names_train)\n",
    "test_size = len(input_file_names_test)\n",
    "dtype = torch.cuda.FloatTensor\n",
    "image_shape = [116, 132, 132]\n",
    "print(train_size, test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model forward (not necessary to run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_file = '/mnt/sdb1/intern_data/pix2pix_wbce_pet3d/train/1_input.npy'\n",
    "input_arr = np.load(input_file).reshape(1,1,116,132,132)\n",
    "input_arr = Variable(torch.from_numpy(input_arr).float().cuda(), volatile = False) # set volatile to false for training\n",
    "model = UNet(n_ch = 1, n_class = 1).cuda()\n",
    "pred_arr = model(input_arr)\n",
    "pred_arr = pred_arr.data.cpu().numpy()\n",
    "pred_arr = pred_arr.reshape(28,44,44)\n",
    "print(pred_arr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get corresponding ground truths (not necessary to run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_file = '/mnt/sdb1/intern_data/pix2pix_wbce_pet3d/train/1_target.npy'\n",
    "target_arr = np.load(target_file)\n",
    "shape = target_arr.shape\n",
    "print('Raw target shape : ', target_arr.shape)\n",
    "target_arr = target_arr[shape[0]//2-14:shape[0]//2+14, shape[1]//2-22:shape[1]//2+22, shape[2]//2-22:shape[2]//2+22]\n",
    "print('Cropped target shape : ', target_arr.shape) # this is the image to train the model with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noise (to be sent to the generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_noise(batch_size, channels = 1, width = 116, height = 132, depth = 132):\n",
    "    z = torch.rand(batch_size, channels, width, height, depth)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bce_loss(scores, target):\n",
    "    neg_abs = -scores.abs()\n",
    "    loss = scores.clamp(min=0) - scores * target + (1 + neg_abs.exp()).log() # numerically stable implementation of binary cross entropy loss\n",
    "    return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator_loss(fake_logits, gentd_output, desired_output, lmbd = 20):\n",
    "    l1 = bce_loss(fake_logits, 1)\n",
    "    n = gentd_output.shape[0]\n",
    "    l2 = ((gentd_output - desired_output) ** 2.0).sum() / n # l2 loss between generated and desired image\n",
    "    loss = l1 + (lmbd * l2) # combining losses\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator_loss(real_logits, fake_logits):\n",
    "    loss = bce_loss(real_logits, 1) + bce_loss(fake_logits, 0)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_optimizer(model):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.00001, betas=(0.5, 0.999))\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(Discriminator, Generator, D_Opti, G_Opti, print_every=100, batch_size=1, num_epochs=10):\n",
    "    i = 0\n",
    "    gen_losses = [] # making a list of the computed losses to be plotted later\n",
    "    disc_losses = []\n",
    "    best_val_loss = 999999\n",
    "    for epoch in range(num_epochs):\n",
    "        disc_iter = batchIterator(input_file_names_train, target_file_names_train, batch_size)\n",
    "        gen_iter = batchIterator(input_file_names_train, target_file_names_train, batch_size)\n",
    "        for _ in range(train_size // batch_size):\n",
    "            input, target = next(disc_iter)\n",
    "            D_Opti.zero_grad()\n",
    "            input_data = Variable(torch.from_numpy(input).float().cuda(), volatile = False)\n",
    "            target_data = Variable(torch.from_numpy(target).float().cuda(), volatile = False)\n",
    "            logits_real = Discriminator(target_data)\n",
    "            g_noise = Variable(sample_noise(batch_size).float().cuda(), volatile = False)\n",
    "            input_data = torch.cat((input_data, g_noise), 1) # combining data with noise for the generator\n",
    "            fake_images = Generator(input_data).detach().view(batch_size, 1, 28, 44, 44)\n",
    "            logits_fake = Discriminator(fake_images)\n",
    "            DiscLoss = discriminator_loss(logits_real, logits_fake)\n",
    "            DiscLoss.backward()\n",
    "            D_Opti.step()\n",
    "            disc_losses.append(DiscLoss.data[0])\n",
    "            # different data for generator and discriminator\n",
    "            gen_input, gen_target = next(gen_iter)\n",
    "            G_Opti.zero_grad()\n",
    "            gen_input_data = Variable(torch.from_numpy(gen_input).float().cuda(), volatile = False)\n",
    "            gen_target_data = Variable(torch.from_numpy(gen_target).float().cuda(), volatile = False)\n",
    "            gen_noise = Variable(sample_noise(batch_size).float().cuda(), volatile = False)\n",
    "            gen_input_data = torch.cat((gen_input_data, gen_noise), 1)\n",
    "            fake_gen_images = Generator(gen_input_data).view(batch_size, 1, 28, 44, 44)\n",
    "            gen_logits_fake = Discriminator(fake_gen_images)\n",
    "            GenLoss = generator_loss(gen_logits_fake, fake_gen_images, gen_target_data)\n",
    "            GenLoss.backward()\n",
    "            G_Opti.step()\n",
    "            gen_losses.append(GenLoss.data[0])\n",
    "            if(i % print_every == 0):\n",
    "                print(\"Iteration number = %d, Discriminator Loss = %f\" % (i, DiscLoss))\n",
    "                print(\"Iteration number = %d, Generator Loss = %f\" % (i, GenLoss))\n",
    "            i+= 1\n",
    "        # validation for best epoch\n",
    "        if (epoch%2 == 0):\n",
    "            val_iter = batchIterator(input_file_names_test, target_file_names_test, batch_size)\n",
    "            val_loss = 0\n",
    "            for _ in range(test_size // batch_size):\n",
    "                test_input, test_target = next(val_iter)\n",
    "                test_input = Variable(torch.from_numpy(test_input).float().cuda(), volatile = True)\n",
    "                test_target = Variable(torch.from_numpy(test_target).float().cuda(), volatile = True)\n",
    "                gen_noise_test = Variable(sample_noise(batch_size).float().cuda(), volatile = True)\n",
    "                gen_input_data_test = torch.cat((test_input, gen_noise_test), 1)\n",
    "                fake_gen_images_test = Generator(gen_input_data_test).view(batch_size, 1, 28, 44, 44)\n",
    "                gen_logits_fake_test = Discriminator(fake_gen_images_test)\n",
    "                GenLoss_test = generator_loss(gen_logits_fake_test, fake_gen_images_test, test_target)\n",
    "                val_loss += GenLoss_test.data[0]\n",
    "            val_loss = val_loss / (test_size // batch_size)\n",
    "            print(\"Epoch = \", epoch, \"val_loss = \", val_loss)\n",
    "            if (val_loss < best_val_loss):\n",
    "                best_val_loss = val_loss\n",
    "                torch.save(Generator.state_dict(), 'models/best_generator.pt')\n",
    "                torch.save(Discriminator.state_dict(), 'models/best_discriminator.pt')\n",
    "        \n",
    "        torch.save(Generator.state_dict(), 'models/generator_bce_epoch'+str(epoch+1)+'.pt')\n",
    "        torch.save(Discriminator.state_dict(), 'models/discriminator_bce_epoch'+str(epoch+1)+'.pt')\n",
    "    plt.figure()\n",
    "    plt.plot(gen_losses)\n",
    "    plt.figure()\n",
    "    plt.plot(disc_losses)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Training the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number = 0, Discriminator Loss = 1.323563\n",
      "Iteration number = 0, Generator Loss = 82624.898438\n",
      "Iteration number = 100, Discriminator Loss = 1.316953\n",
      "Iteration number = 100, Generator Loss = 15872.484375\n",
      "Iteration number = 200, Discriminator Loss = 1.165173\n",
      "Iteration number = 200, Generator Loss = 6273.446777\n",
      "Iteration number = 300, Discriminator Loss = 1.522403\n",
      "Iteration number = 300, Generator Loss = 7133.627441\n",
      "Iteration number = 400, Discriminator Loss = 1.285836\n",
      "Iteration number = 400, Generator Loss = 33684.703125\n",
      "Iteration number = 500, Discriminator Loss = 1.086105\n",
      "Iteration number = 500, Generator Loss = 9425.375977\n",
      "Iteration number = 600, Discriminator Loss = 1.152814\n",
      "Iteration number = 600, Generator Loss = 7410.121582\n",
      "Iteration number = 700, Discriminator Loss = 0.995198\n",
      "Iteration number = 700, Generator Loss = 5535.256348\n",
      "Iteration number = 800, Discriminator Loss = 1.062833\n",
      "Iteration number = 800, Generator Loss = 5293.995117\n",
      "Iteration number = 900, Discriminator Loss = 0.955307\n",
      "Iteration number = 900, Generator Loss = 2488.055176\n",
      "Iteration number = 1000, Discriminator Loss = 0.526299\n",
      "Iteration number = 1000, Generator Loss = 2144.903320\n",
      "Iteration number = 1100, Discriminator Loss = 0.938818\n",
      "Iteration number = 1100, Generator Loss = 107492.828125\n",
      "Iteration number = 1200, Discriminator Loss = 0.915242\n",
      "Iteration number = 1200, Generator Loss = 15115.380859\n",
      "Iteration number = 1300, Discriminator Loss = 0.699126\n",
      "Iteration number = 1300, Generator Loss = 1956.873535\n",
      "Iteration number = 1400, Discriminator Loss = 0.754981\n",
      "Iteration number = 1400, Generator Loss = 2697.984131\n",
      "Iteration number = 1500, Discriminator Loss = 0.731552\n",
      "Iteration number = 1500, Generator Loss = 3974.781738\n",
      "Iteration number = 1600, Discriminator Loss = 0.758113\n",
      "Iteration number = 1600, Generator Loss = 151560.812500\n",
      "Iteration number = 1700, Discriminator Loss = 0.337525\n",
      "Iteration number = 1700, Generator Loss = 7166.047852\n",
      "Iteration number = 1800, Discriminator Loss = 2.472316\n",
      "Iteration number = 1800, Generator Loss = 2529.095703\n",
      "Iteration number = 1900, Discriminator Loss = 0.576640\n",
      "Iteration number = 1900, Generator Loss = 14754.987305\n",
      "Epoch =  0 val_loss =  16686.153106572077\n",
      "Iteration number = 2000, Discriminator Loss = 0.563272\n",
      "Iteration number = 2000, Generator Loss = 1024.313721\n",
      "Iteration number = 2100, Discriminator Loss = 0.880454\n",
      "Iteration number = 2100, Generator Loss = 3270.616699\n",
      "Iteration number = 2200, Discriminator Loss = 1.281698\n",
      "Iteration number = 2200, Generator Loss = 12132.183594\n",
      "Iteration number = 2300, Discriminator Loss = 0.311459\n",
      "Iteration number = 2300, Generator Loss = 2617.464600\n",
      "Iteration number = 2400, Discriminator Loss = 0.730908\n",
      "Iteration number = 2400, Generator Loss = 65140.531250\n",
      "Iteration number = 2500, Discriminator Loss = 0.570427\n",
      "Iteration number = 2500, Generator Loss = 4178.027344\n",
      "Iteration number = 2600, Discriminator Loss = 0.231248\n",
      "Iteration number = 2600, Generator Loss = 8545.587891\n",
      "Iteration number = 2700, Discriminator Loss = 0.853626\n",
      "Iteration number = 2700, Generator Loss = 2415.907471\n",
      "Iteration number = 2800, Discriminator Loss = 0.319837\n",
      "Iteration number = 2800, Generator Loss = 865.112183\n",
      "Iteration number = 2900, Discriminator Loss = 1.407331\n",
      "Iteration number = 2900, Generator Loss = 1186.064453\n",
      "Iteration number = 3000, Discriminator Loss = 0.297108\n",
      "Iteration number = 3000, Generator Loss = 4931.727051\n",
      "Iteration number = 3100, Discriminator Loss = 0.278294\n",
      "Iteration number = 3100, Generator Loss = 8737.155273\n",
      "Iteration number = 3200, Discriminator Loss = 0.165865\n",
      "Iteration number = 3200, Generator Loss = 9899.899414\n",
      "Iteration number = 3300, Discriminator Loss = 0.507715\n",
      "Iteration number = 3300, Generator Loss = 833.861328\n",
      "Iteration number = 3400, Discriminator Loss = 0.423694\n",
      "Iteration number = 3400, Generator Loss = 2266.758301\n",
      "Iteration number = 3500, Discriminator Loss = 0.664140\n",
      "Iteration number = 3500, Generator Loss = 91645.945312\n",
      "Iteration number = 3600, Discriminator Loss = 0.219442\n",
      "Iteration number = 3600, Generator Loss = 4170.857422\n",
      "Iteration number = 3700, Discriminator Loss = 0.944029\n",
      "Iteration number = 3700, Generator Loss = 1255.126587\n",
      "Iteration number = 3800, Discriminator Loss = 0.141914\n",
      "Iteration number = 3800, Generator Loss = 2130.769043\n",
      "Iteration number = 3900, Discriminator Loss = 0.366961\n",
      "Iteration number = 3900, Generator Loss = 152868.265625\n",
      "Iteration number = 4000, Discriminator Loss = 0.188746\n",
      "Iteration number = 4000, Generator Loss = 2910.820312\n",
      "Iteration number = 4100, Discriminator Loss = 0.453625\n",
      "Iteration number = 4100, Generator Loss = 1224.519653\n",
      "Iteration number = 4200, Discriminator Loss = 0.144802\n",
      "Iteration number = 4200, Generator Loss = 1818.341064\n",
      "Iteration number = 4300, Discriminator Loss = 0.165673\n",
      "Iteration number = 4300, Generator Loss = 6474.122559\n",
      "Iteration number = 4400, Discriminator Loss = 0.142062\n",
      "Iteration number = 4400, Generator Loss = 987.537537\n",
      "Iteration number = 4500, Discriminator Loss = 0.352918\n",
      "Iteration number = 4500, Generator Loss = 1045.699097\n",
      "Iteration number = 4600, Discriminator Loss = 0.128682\n",
      "Iteration number = 4600, Generator Loss = 787.518372\n",
      "Iteration number = 4700, Discriminator Loss = 0.151651\n",
      "Iteration number = 4700, Generator Loss = 919.578857\n",
      "Iteration number = 4800, Discriminator Loss = 0.728375\n",
      "Iteration number = 4800, Generator Loss = 697.966736\n",
      "Iteration number = 4900, Discriminator Loss = 0.368530\n",
      "Iteration number = 4900, Generator Loss = 702.996704\n",
      "Iteration number = 5000, Discriminator Loss = 0.074761\n",
      "Iteration number = 5000, Generator Loss = 13211.599609\n",
      "Iteration number = 5100, Discriminator Loss = 0.517130\n",
      "Iteration number = 5100, Generator Loss = 2447.025879\n",
      "Iteration number = 5200, Discriminator Loss = 0.076461\n",
      "Iteration number = 5200, Generator Loss = 1369.664551\n",
      "Iteration number = 5300, Discriminator Loss = 0.442710\n",
      "Iteration number = 5300, Generator Loss = 718.811401\n",
      "Iteration number = 5400, Discriminator Loss = 1.399264\n",
      "Iteration number = 5400, Generator Loss = 9933.606445\n",
      "Iteration number = 5500, Discriminator Loss = 0.135817\n",
      "Iteration number = 5500, Generator Loss = 87011.570312\n",
      "Iteration number = 5600, Discriminator Loss = 0.943597\n",
      "Iteration number = 5600, Generator Loss = 24165.164062\n",
      "Iteration number = 5700, Discriminator Loss = 0.096071\n",
      "Iteration number = 5700, Generator Loss = 873.326599\n",
      "Iteration number = 5800, Discriminator Loss = 0.334403\n",
      "Iteration number = 5800, Generator Loss = 2141.585938\n",
      "Iteration number = 5900, Discriminator Loss = 0.054370\n",
      "Iteration number = 5900, Generator Loss = 4100.688477\n",
      "Epoch =  2 val_loss =  7802.2481791569635\n",
      "Iteration number = 6000, Discriminator Loss = 0.348232\n",
      "Iteration number = 6000, Generator Loss = 32547.830078\n",
      "Iteration number = 6100, Discriminator Loss = 0.211826\n",
      "Iteration number = 6100, Generator Loss = 861.777649\n",
      "Iteration number = 6200, Discriminator Loss = 0.207489\n",
      "Iteration number = 6200, Generator Loss = 963.730774\n",
      "Iteration number = 6300, Discriminator Loss = 1.128672\n",
      "Iteration number = 6300, Generator Loss = 504.693939\n",
      "Iteration number = 6400, Discriminator Loss = 0.495696\n",
      "Iteration number = 6400, Generator Loss = 461.736542\n",
      "Iteration number = 6500, Discriminator Loss = 0.101816\n",
      "Iteration number = 6500, Generator Loss = 806.670776\n",
      "Iteration number = 6600, Discriminator Loss = 0.053333\n",
      "Iteration number = 6600, Generator Loss = 19286.822266\n",
      "Iteration number = 6700, Discriminator Loss = 0.423656\n",
      "Iteration number = 6700, Generator Loss = 483.850555\n",
      "Iteration number = 6800, Discriminator Loss = 0.067213\n",
      "Iteration number = 6800, Generator Loss = 468.221283\n",
      "Iteration number = 6900, Discriminator Loss = 0.089066\n",
      "Iteration number = 6900, Generator Loss = 472.442963\n",
      "Iteration number = 7000, Discriminator Loss = 0.078897\n",
      "Iteration number = 7000, Generator Loss = 14495.653320\n",
      "Iteration number = 7100, Discriminator Loss = 0.130560\n",
      "Iteration number = 7100, Generator Loss = 457.872498\n",
      "Iteration number = 7200, Discriminator Loss = 0.065873\n",
      "Iteration number = 7200, Generator Loss = 9501.458008\n",
      "Iteration number = 7300, Discriminator Loss = 1.120814\n",
      "Iteration number = 7300, Generator Loss = 456.260559\n",
      "Iteration number = 7400, Discriminator Loss = 0.042162\n",
      "Iteration number = 7400, Generator Loss = 4423.652832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number = 7500, Discriminator Loss = 0.248884\n",
      "Iteration number = 7500, Generator Loss = 653.308594\n",
      "Iteration number = 7600, Discriminator Loss = 0.062008\n",
      "Iteration number = 7600, Generator Loss = 36655.527344\n",
      "Iteration number = 7700, Discriminator Loss = 0.158150\n",
      "Iteration number = 7700, Generator Loss = 3582.761963\n",
      "Iteration number = 7800, Discriminator Loss = 0.324748\n",
      "Iteration number = 7800, Generator Loss = 356.391296\n",
      "Iteration number = 7900, Discriminator Loss = 0.129256\n",
      "Iteration number = 7900, Generator Loss = 386.275238\n",
      "Iteration number = 8000, Discriminator Loss = 0.312315\n",
      "Iteration number = 8000, Generator Loss = 307.162262\n",
      "Iteration number = 8100, Discriminator Loss = 0.043343\n",
      "Iteration number = 8100, Generator Loss = 4976.629395\n",
      "Iteration number = 8200, Discriminator Loss = 0.288845\n",
      "Iteration number = 8200, Generator Loss = 686.850098\n",
      "Iteration number = 8300, Discriminator Loss = 0.068151\n",
      "Iteration number = 8300, Generator Loss = 195.185242\n",
      "Iteration number = 8400, Discriminator Loss = 0.054701\n",
      "Iteration number = 8400, Generator Loss = 234.974106\n",
      "Iteration number = 8500, Discriminator Loss = 0.278945\n",
      "Iteration number = 8500, Generator Loss = 249.123993\n",
      "Iteration number = 8600, Discriminator Loss = 0.144317\n",
      "Iteration number = 8600, Generator Loss = 218.727081\n",
      "Iteration number = 8700, Discriminator Loss = 0.127330\n",
      "Iteration number = 8700, Generator Loss = 42717.964844\n",
      "Iteration number = 8800, Discriminator Loss = 0.263767\n",
      "Iteration number = 8800, Generator Loss = 401.113831\n",
      "Iteration number = 8900, Discriminator Loss = 0.035860\n",
      "Iteration number = 8900, Generator Loss = 194.307327\n",
      "Iteration number = 9000, Discriminator Loss = 0.185236\n",
      "Iteration number = 9000, Generator Loss = 735.175232\n",
      "Iteration number = 9100, Discriminator Loss = 0.158221\n",
      "Iteration number = 9100, Generator Loss = 10592.434570\n",
      "Iteration number = 9200, Discriminator Loss = 0.843052\n",
      "Iteration number = 9200, Generator Loss = 7735.703613\n",
      "Iteration number = 9300, Discriminator Loss = 0.048537\n",
      "Iteration number = 9300, Generator Loss = 274.353577\n",
      "Iteration number = 9400, Discriminator Loss = 0.030940\n",
      "Iteration number = 9400, Generator Loss = 2124.387207\n",
      "Iteration number = 9500, Discriminator Loss = 0.240600\n",
      "Iteration number = 9500, Generator Loss = 183.523087\n",
      "Iteration number = 9600, Discriminator Loss = 0.042648\n",
      "Iteration number = 9600, Generator Loss = 4819.363281\n",
      "Iteration number = 9700, Discriminator Loss = 0.015850\n",
      "Iteration number = 9700, Generator Loss = 34937.144531\n",
      "Iteration number = 9800, Discriminator Loss = 0.041317\n",
      "Iteration number = 9800, Generator Loss = 7711.875488\n",
      "Iteration number = 9900, Discriminator Loss = 0.462656\n",
      "Iteration number = 9900, Generator Loss = 1371.660278\n",
      "Epoch =  4 val_loss =  6897.111917304993\n",
      "Iteration number = 10000, Discriminator Loss = 0.181915\n",
      "Iteration number = 10000, Generator Loss = 3048.626953\n",
      "Iteration number = 10100, Discriminator Loss = 0.074811\n",
      "Iteration number = 10100, Generator Loss = 23547.042969\n",
      "Iteration number = 10200, Discriminator Loss = 0.038473\n",
      "Iteration number = 10200, Generator Loss = 133.789871\n",
      "Iteration number = 10300, Discriminator Loss = 0.030255\n",
      "Iteration number = 10300, Generator Loss = 334.680359\n",
      "Iteration number = 10400, Discriminator Loss = 0.026017\n",
      "Iteration number = 10400, Generator Loss = 158.344955\n",
      "Iteration number = 10500, Discriminator Loss = 0.167821\n",
      "Iteration number = 10500, Generator Loss = 116.395035\n",
      "Iteration number = 10600, Discriminator Loss = 0.019735\n",
      "Iteration number = 10600, Generator Loss = 129933.718750\n",
      "Iteration number = 10700, Discriminator Loss = 0.024471\n",
      "Iteration number = 10700, Generator Loss = 6101.569824\n",
      "Iteration number = 10800, Discriminator Loss = 0.120107\n",
      "Iteration number = 10800, Generator Loss = 347.117462\n",
      "Iteration number = 10900, Discriminator Loss = 0.020505\n",
      "Iteration number = 10900, Generator Loss = 153.127106\n",
      "Iteration number = 11000, Discriminator Loss = 0.038468\n",
      "Iteration number = 11000, Generator Loss = 454.227478\n",
      "Iteration number = 11100, Discriminator Loss = 0.046602\n",
      "Iteration number = 11100, Generator Loss = 160.010025\n",
      "Iteration number = 11200, Discriminator Loss = 0.062366\n",
      "Iteration number = 11200, Generator Loss = 4554.531250\n",
      "Iteration number = 11300, Discriminator Loss = 0.014464\n",
      "Iteration number = 11300, Generator Loss = 5434.085449\n",
      "Iteration number = 11400, Discriminator Loss = 0.016704\n",
      "Iteration number = 11400, Generator Loss = 617.037781\n",
      "Iteration number = 11500, Discriminator Loss = 0.024228\n",
      "Iteration number = 11500, Generator Loss = 12559.037109\n",
      "Iteration number = 11600, Discriminator Loss = 0.028405\n",
      "Iteration number = 11600, Generator Loss = 1651.138306\n",
      "Iteration number = 11700, Discriminator Loss = 0.015936\n",
      "Iteration number = 11700, Generator Loss = 305.171082\n",
      "Iteration number = 11800, Discriminator Loss = 0.015583\n",
      "Iteration number = 11800, Generator Loss = 409.402527\n",
      "Iteration number = 11900, Discriminator Loss = 0.059233\n",
      "Iteration number = 11900, Generator Loss = 195.114288\n",
      "Iteration number = 12000, Discriminator Loss = 0.031756\n",
      "Iteration number = 12000, Generator Loss = 264.283600\n",
      "Iteration number = 12100, Discriminator Loss = 0.129050\n",
      "Iteration number = 12100, Generator Loss = 136.111710\n",
      "Iteration number = 12200, Discriminator Loss = 0.019783\n",
      "Iteration number = 12200, Generator Loss = 66786.726562\n",
      "Iteration number = 12300, Discriminator Loss = 0.061105\n",
      "Iteration number = 12300, Generator Loss = 275.253021\n",
      "Iteration number = 12400, Discriminator Loss = 0.016531\n",
      "Iteration number = 12400, Generator Loss = 360.957916\n",
      "Iteration number = 12500, Discriminator Loss = 0.016717\n",
      "Iteration number = 12500, Generator Loss = 177.207382\n",
      "Iteration number = 12600, Discriminator Loss = 0.027398\n",
      "Iteration number = 12600, Generator Loss = 1185.794800\n",
      "Iteration number = 12700, Discriminator Loss = 0.111361\n",
      "Iteration number = 12700, Generator Loss = 145.676575\n",
      "Iteration number = 12800, Discriminator Loss = 0.023685\n",
      "Iteration number = 12800, Generator Loss = 2326.242676\n",
      "Iteration number = 12900, Discriminator Loss = 0.025250\n",
      "Iteration number = 12900, Generator Loss = 204.828415\n",
      "Iteration number = 13000, Discriminator Loss = 0.053904\n",
      "Iteration number = 13000, Generator Loss = 193.493607\n",
      "Iteration number = 13100, Discriminator Loss = 0.018590\n",
      "Iteration number = 13100, Generator Loss = 196.123154\n",
      "Iteration number = 13200, Discriminator Loss = 0.160215\n",
      "Iteration number = 13200, Generator Loss = 356.614410\n",
      "Iteration number = 13300, Discriminator Loss = 0.075159\n",
      "Iteration number = 13300, Generator Loss = 21666.794922\n",
      "Iteration number = 13400, Discriminator Loss = 0.042794\n",
      "Iteration number = 13400, Generator Loss = 203.442902\n",
      "Iteration number = 13500, Discriminator Loss = 0.015420\n",
      "Iteration number = 13500, Generator Loss = 574.018738\n",
      "Iteration number = 13600, Discriminator Loss = 0.012934\n",
      "Iteration number = 13600, Generator Loss = 3896.826416\n",
      "Iteration number = 13700, Discriminator Loss = 0.198747\n",
      "Iteration number = 13700, Generator Loss = 2159.610352\n",
      "Iteration number = 13800, Discriminator Loss = 0.059992\n",
      "Iteration number = 13800, Generator Loss = 89.848412\n",
      "Iteration number = 13900, Discriminator Loss = 0.024790\n",
      "Iteration number = 13900, Generator Loss = 16018.541992\n",
      "Epoch =  6 val_loss =  6214.185668666546\n",
      "Iteration number = 14000, Discriminator Loss = 0.073518\n",
      "Iteration number = 14000, Generator Loss = 16508.041016\n",
      "Iteration number = 14100, Discriminator Loss = 0.020846\n",
      "Iteration number = 14100, Generator Loss = 226.144775\n",
      "Iteration number = 14200, Discriminator Loss = 0.139483\n",
      "Iteration number = 14200, Generator Loss = 124.181885\n",
      "Iteration number = 14300, Discriminator Loss = 0.030958\n",
      "Iteration number = 14300, Generator Loss = 436.817322\n",
      "Iteration number = 14400, Discriminator Loss = 0.071468\n",
      "Iteration number = 14400, Generator Loss = 123.240517\n",
      "Iteration number = 14500, Discriminator Loss = 0.018755\n",
      "Iteration number = 14500, Generator Loss = 685.879517\n",
      "Iteration number = 14600, Discriminator Loss = 0.014665\n",
      "Iteration number = 14600, Generator Loss = 2767.281738\n",
      "Iteration number = 14700, Discriminator Loss = 0.013032\n",
      "Iteration number = 14700, Generator Loss = 1365.911621\n",
      "Iteration number = 14800, Discriminator Loss = 0.013752\n",
      "Iteration number = 14800, Generator Loss = 363.997284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number = 14900, Discriminator Loss = 0.022803\n",
      "Iteration number = 14900, Generator Loss = 154631.046875\n",
      "Iteration number = 15000, Discriminator Loss = 0.019675\n",
      "Iteration number = 15000, Generator Loss = 272.692169\n",
      "Iteration number = 15100, Discriminator Loss = 0.013946\n",
      "Iteration number = 15100, Generator Loss = 9583.496094\n",
      "Iteration number = 15200, Discriminator Loss = 0.012430\n",
      "Iteration number = 15200, Generator Loss = 103.536606\n",
      "Iteration number = 15300, Discriminator Loss = 0.013218\n",
      "Iteration number = 15300, Generator Loss = 636.075317\n",
      "Iteration number = 15400, Discriminator Loss = 0.013339\n",
      "Iteration number = 15400, Generator Loss = 93.644516\n",
      "Iteration number = 15500, Discriminator Loss = 0.014082\n",
      "Iteration number = 15500, Generator Loss = 81.049255\n",
      "Iteration number = 15600, Discriminator Loss = 0.012461\n",
      "Iteration number = 15600, Generator Loss = 7244.620117\n",
      "Iteration number = 15700, Discriminator Loss = 0.018025\n",
      "Iteration number = 15700, Generator Loss = 237.912155\n",
      "Iteration number = 15800, Discriminator Loss = 0.033996\n",
      "Iteration number = 15800, Generator Loss = 72.008827\n",
      "Iteration number = 15900, Discriminator Loss = 0.063436\n",
      "Iteration number = 15900, Generator Loss = 194.061737\n",
      "Iteration number = 16000, Discriminator Loss = 0.013296\n",
      "Iteration number = 16000, Generator Loss = 127.423225\n",
      "Iteration number = 16100, Discriminator Loss = 0.010269\n",
      "Iteration number = 16100, Generator Loss = 108.169495\n",
      "Iteration number = 16200, Discriminator Loss = 0.027223\n",
      "Iteration number = 16200, Generator Loss = 5278.170410\n",
      "Iteration number = 16300, Discriminator Loss = 0.026533\n",
      "Iteration number = 16300, Generator Loss = 1420.169434\n",
      "Iteration number = 16400, Discriminator Loss = 0.016159\n",
      "Iteration number = 16400, Generator Loss = 3742.159912\n",
      "Iteration number = 16500, Discriminator Loss = 0.057214\n",
      "Iteration number = 16500, Generator Loss = 5820.133301\n",
      "Iteration number = 16600, Discriminator Loss = 0.024773\n",
      "Iteration number = 16600, Generator Loss = 257.449097\n",
      "Iteration number = 16700, Discriminator Loss = 0.004784\n",
      "Iteration number = 16700, Generator Loss = 1248.279541\n",
      "Iteration number = 16800, Discriminator Loss = 0.319632\n",
      "Iteration number = 16800, Generator Loss = 106.773964\n",
      "Iteration number = 16900, Discriminator Loss = 0.008014\n",
      "Iteration number = 16900, Generator Loss = 152.469803\n",
      "Iteration number = 17000, Discriminator Loss = 0.126700\n",
      "Iteration number = 17000, Generator Loss = 9028.713867\n",
      "Iteration number = 17100, Discriminator Loss = 0.008666\n",
      "Iteration number = 17100, Generator Loss = 843.563354\n",
      "Iteration number = 17200, Discriminator Loss = 0.009998\n",
      "Iteration number = 17200, Generator Loss = 140.951874\n",
      "Iteration number = 17300, Discriminator Loss = 0.092190\n",
      "Iteration number = 17300, Generator Loss = 202.529846\n",
      "Iteration number = 17400, Discriminator Loss = 0.079793\n",
      "Iteration number = 17400, Generator Loss = 90.506683\n",
      "Iteration number = 17500, Discriminator Loss = 0.071736\n",
      "Iteration number = 17500, Generator Loss = 1077.948364\n",
      "Iteration number = 17600, Discriminator Loss = 0.016786\n",
      "Iteration number = 17600, Generator Loss = 15864.479492\n",
      "Iteration number = 17700, Discriminator Loss = 0.006589\n",
      "Iteration number = 17700, Generator Loss = 210.325455\n",
      "Iteration number = 17800, Discriminator Loss = 0.100840\n",
      "Iteration number = 17800, Generator Loss = 100.930580\n",
      "Iteration number = 17900, Discriminator Loss = 0.089350\n",
      "Iteration number = 17900, Generator Loss = 1324.473145\n",
      "Epoch =  8 val_loss =  6371.98444990745\n",
      "Iteration number = 18000, Discriminator Loss = 0.008388\n",
      "Iteration number = 18000, Generator Loss = 76.135468\n",
      "Iteration number = 18100, Discriminator Loss = 0.008620\n",
      "Iteration number = 18100, Generator Loss = 140.713120\n",
      "Iteration number = 18200, Discriminator Loss = 0.021541\n",
      "Iteration number = 18200, Generator Loss = 50.094719\n",
      "Iteration number = 18300, Discriminator Loss = 0.055074\n",
      "Iteration number = 18300, Generator Loss = 1004.972534\n",
      "Iteration number = 18400, Discriminator Loss = 0.018123\n",
      "Iteration number = 18400, Generator Loss = 46.339252\n",
      "Iteration number = 18500, Discriminator Loss = 0.015483\n",
      "Iteration number = 18500, Generator Loss = 8730.412109\n",
      "Iteration number = 18600, Discriminator Loss = 0.010268\n",
      "Iteration number = 18600, Generator Loss = 115.688774\n",
      "Iteration number = 18700, Discriminator Loss = 0.007209\n",
      "Iteration number = 18700, Generator Loss = 39099.960938\n",
      "Iteration number = 18800, Discriminator Loss = 0.015224\n",
      "Iteration number = 18800, Generator Loss = 115.256454\n",
      "Iteration number = 18900, Discriminator Loss = 0.022786\n",
      "Iteration number = 18900, Generator Loss = 26599.599609\n",
      "Iteration number = 19000, Discriminator Loss = 0.020580\n",
      "Iteration number = 19000, Generator Loss = 8561.449219\n",
      "Iteration number = 19100, Discriminator Loss = 0.037663\n",
      "Iteration number = 19100, Generator Loss = 139.251862\n",
      "Iteration number = 19200, Discriminator Loss = 0.112045\n",
      "Iteration number = 19200, Generator Loss = 52.651779\n",
      "Iteration number = 19300, Discriminator Loss = 0.016115\n",
      "Iteration number = 19300, Generator Loss = 73.704933\n",
      "Iteration number = 19400, Discriminator Loss = 0.028152\n",
      "Iteration number = 19400, Generator Loss = 96.192780\n",
      "Iteration number = 19500, Discriminator Loss = 0.047811\n",
      "Iteration number = 19500, Generator Loss = 69358.648438\n",
      "Iteration number = 19600, Discriminator Loss = 0.094378\n",
      "Iteration number = 19600, Generator Loss = 1874.477173\n",
      "Iteration number = 19700, Discriminator Loss = 0.004301\n",
      "Iteration number = 19700, Generator Loss = 209.890442\n",
      "Iteration number = 19800, Discriminator Loss = 0.116262\n",
      "Iteration number = 19800, Generator Loss = 3754.550293\n",
      "Iteration number = 19900, Discriminator Loss = 0.007867\n",
      "Iteration number = 19900, Generator Loss = 68.898857\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAD8CAYAAACLrvgBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAb+bYppLnhVmAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4be25d6d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEXkQkzsRkQcxuRMRedD/B03qmDoOP6bpAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4bdb6bd748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Discriminator = DiscConvNet(image_shape).type(dtype)\n",
    "Generator = UNet(n_ch = 2, n_class = 1).type(dtype)\n",
    "D_Opti = get_optimizer(Discriminator)\n",
    "G_Opti = get_optimizer(Generator)\n",
    "train(Discriminator, Generator, D_Opti, G_Opti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
