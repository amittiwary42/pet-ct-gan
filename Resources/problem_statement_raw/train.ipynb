{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from model import UNet\n",
    "import os\n",
    "import numpy as np\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = '/mnt/sdb1/intern_data/pix2pix_wbce_pet3d/train/1_input.npy'\n",
    "input_arr = np.load(input_file).reshape(1,1,116,132,132)\n",
    "input_arr = Variable(torch.from_numpy(input_arr).float().cuda(), volatile = False) # set volatile to false for training\n",
    "model = UNet(n_ch = 1, n_class = 1).cuda()\n",
    "pred_arr = model(input_arr)\n",
    "pred_arr = pred_arr.data.cpu().numpy()\n",
    "pred_arr = pred_arr.reshape(28,44,44)\n",
    "print(pred_arr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get corresponding ground truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_file = '/mnt/sdb1/intern_data/pix2pix_wbce_pet3d/train/1_target.npy'\n",
    "target_arr = np.load(target_file)\n",
    "shape = target_arr.shape\n",
    "print('Raw target shape : ', target_arr.shape)\n",
    "target_arr = target_arr[shape[0]//2-14:shape[0]//2+14, shape[1]//2-22:shape[1]//2+22, shape[2]//2-22:shape[2]//2+22]\n",
    "print('Cropped target shape : ', target_arr.shape) # this is the image to train the model with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bce_loss(scores, target):\n",
    "    neg_abs = -scores.abs()\n",
    "    loss = scores.clamp(min=0) - scores * target + (1 + neg_abs.exp()).log()\n",
    "    return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator_loss(fake_logits):\n",
    "    loss = bce_loss(fake_logits, 1)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator_loss(real_logits, fake_logits):\n",
    "    loss = bce_loss(real_logits, 1) + bce_loss(fake_logits, 0)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_optimizer(model):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.00001, betas=(0.5, 0.999))\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(Discriminator, Generator, D_Opti, G_Opti, D_Loss, G_Loss, print_every=100, batch_size=32, num_epochs=20):\n",
    "    i = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        for _ in range(train_size // batch_size):\n",
    "            input, target = data_batcher.getNextBatch(batch_size)\n",
    "            \n",
    "            D_Opti.zero_grad()\n",
    "            input_data = Variable(input).type(dtype)\n",
    "            target_data = Variable(target).type(dtype)\n",
    "            logits_real = Discriminator(target_data)\n",
    "            fake_images = Generator(input_data)\n",
    "            logits_fake = Discriminator(fake_images)\n",
    "            DiscLoss = D_Loss(logits_real, logits_fake)\n",
    "            DiscLoss.backward()\n",
    "            D_Opti.step()\n",
    "            \n",
    "            G_opti.zero_grad()\n",
    "            GenLoss = G_Loss(logits_fake)\n",
    "            GenLoss.backward()\n",
    "            G_Opti.step()\n",
    "            \n",
    "            if(i % print_every == 0):\n",
    "                print(\"Discriminator Loss = \", DiscLoss)\n",
    "                print(\"Generator Loss = \", GenLoss)\n",
    "                \n",
    "            i+= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
